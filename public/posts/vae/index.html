<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>An Overview of Autoencoders | Dev&#39;s Blog</title>
<meta name="keywords" content="machine learning, python, deep learning">
<meta name="description" content="Hey guys! For my 2-D Ising Model project, I was reading up on Denoising Diffusion Probabilistic Models (DDPMs), which are generative models used in machine learning – especially for generating images. To better understand how DDPMs work, I decided to explore some of the foundational models they build upon, which led me to autoencoders.
In this post, I’ll give a brief overview of autoencoders and introduce two important variants: the variational autoencoder (VAE) and the sparse autoencoder (SAE).">
<meta name="author" content="Dev Desai">
<link rel="canonical" href="http://localhost:1313/posts/vae/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css" integrity="sha256-j&#43;ECM6cGvIfy4Is8&#43;XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/vae/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
    
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  MathJax = {
    tex: {
      displayMath: [['\\[', '\\]'], ['$$', '$$']],  
      inlineMath: [['\\(', '\\)'], ['$','$']]
    }
  };
</script>
    
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Dev&#39;s Blog (Alt + H)">Dev&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/posts/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      An Overview of Autoencoders
    </h1>
    <div class="post-meta"><span title='2025-07-22 18:47:40 -0600 -0600'>July 22, 2025</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Dev Desai

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#autoencoders" aria-label="Autoencoders">Autoencoders</a></li>
                <li>
                    <a href="#sparse-autoencoders" aria-label="Sparse Autoencoders">Sparse Autoencoders</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>Hey guys! For my 2-D Ising Model project, I was reading up on <em>Denoising Diffusion Probabilistic Models</em> (DDPMs), which are generative models used in machine learning – especially for generating images. To better understand how DDPMs work, I decided to explore some of the foundational models they build upon, which led me to autoencoders.</p>
<p>In this post, I’ll give a brief overview of autoencoders and introduce two important variants: the <strong>variational autoencoder (VAE)</strong> and the <strong>sparse autoencoder (SAE)</strong>.</p>
<h2 id="autoencoders">Autoencoders<a hidden class="anchor" aria-hidden="true" href="#autoencoders">#</a></h2>
<p>Firstly, what exactly is an autoencoder? Simply put, an autoencoder is a neural network which compresses data ($X$) into a lower dimensional representation, called the <em>latent space (Z)</em> and reconstructs it back to its original form.</p>
<p>It consists of two main components:</p>
<ul>
<li><strong>Encoder</strong>: Maps the input data $x$ to a latent vector $z$</li>
<li><strong>Decoder</strong>: Maps the latent vector $z$ to a reconstructed vector $\hat x$</li>
</ul>
<p>where $\mathbf x$, $\hat{\mathbf x}$ $\in X$ and $\mathbf z\in Z$.</p>
<figure class="align-center ">
    <img loading="lazy" src="./images/autoencoder.png#center"
         alt="A basic autoencoder architecture: the encoder compresses the input into a latent space, and the decoder reconstructs the input from this representation. Note, in this image, there is only one hidden layer, but deep autoencoders may have multiple in the encoder and decoder." width="500px"/> <figcaption>
            <p>A basic autoencoder architecture: the encoder compresses the input into a latent space, and the decoder reconstructs the input from this representation. Note, in this image, there is only one hidden layer, but deep autoencoders may have multiple in the encoder and decoder.</p>
        </figcaption>
</figure>

<p>The goal is for $\hat{x}$ to be as close as possible to $x$, hence when training the model, our loss function will typically be the L2 Reconstruction Loss.</p>
<p>$$\mathcal{L}_{\text{recon}} = | \mathbf{x} - \hat{\mathbf{x}} |^2$$</p>
<p>Note that this model is not generative but rather aims to retain important information and reconstruct the compressed input vector. Next, let&rsquo;s explore sparse autoencoders (SAEs), which have a small twist from the standard autoencoder to promote feature selection.</p>
<hr>
<h2 id="sparse-autoencoders">Sparse Autoencoders<a hidden class="anchor" aria-hidden="true" href="#sparse-autoencoders">#</a></h2>
<p>I first heard of sparse autoencoders when my friend introduced a project on the mechanistic interpretability of large language models. In theory, a sparse autoencoder could be stuck inside of a neural network as a probe to help us see &ldquo;features&rdquo; that the model is learning. Before we dive into what SAE&rsquo;s are, here&rsquo;s a bit more about the motivation behind them.</p>
<p>Neural networks are highly complex, non-linear functions which rely on a concept called <em>polysemanticity</em> to model such complex datasets without blowing up their parameter space.</p>
<blockquote>
<p><em>Polysemanticity</em> refers to how individual neurons do not represent singular features in the model. Instead, each neuron can activate in response to many different, seemingly unrelated patterns.</p></blockquote>
<p>It&rsquo;s the combination of these overlapping activations that allows the network to represent rich, complex models. This same strength that neural networks have is also what makes it difficult to interpret what it is actually &ldquo;thinking.&rdquo; Sparse autoencoders aim to aid in this.</p>
<p>There are two key ideas that differ an SAE from an AE which could help us interpret a neural network:</p>
<blockquote>
<ol>
<li>The latent space should be large (we can have more neurons in the latent layer than the input layer).</li>
<li>We add a sparsity term in the loss function to encourage the activations of neurons to be close to 0.</li>
</ol></blockquote>
<p>SAE&rsquo;s do not aim to &ldquo;compress&rdquo; the input data and reconstruct it. Rather, their purpose is to try to understand what the model could be &ldquo;thinking&rdquo;. Typically, we want to keep the dimensionality of the latent space lower to help with the curse of dimensionality (overfitting, being computationally difficult to train a high dimensional model), and neural networks work due to the idea of</p>
<p>Sources:
Image 1: <a href="https://www.geeksforgeeks.org/machine-learning/auto-encoders/">https://www.geeksforgeeks.org/machine-learning/auto-encoders/</a></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/machine-learning/">Machine Learning</a></li>
      <li><a href="http://localhost:1313/tags/python/">Python</a></li>
      <li><a href="http://localhost:1313/tags/deep-learning/">Deep Learning</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">Dev&#39;s Blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>